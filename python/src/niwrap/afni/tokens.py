# This file was auto generated by Styx.
# Do not edit this file directly.

from styxdefs import *
import pathlib
import typing

TOKENS_METADATA = Metadata(
    id="5fb7124f19d181ab8cc146095dd8decdcfe3daaa",
    name="tokens",
    container_image_type="docker",
    container_image_tag="fcpindi/c-pac:latest",
)


class TokensOutputs(typing.NamedTuple):
    """
    Output object returned when calling `tokens(...)`.
    """
    root: OutputPathType
    """Output root folder. This is the root folder for all outputs."""


def tokens(
    infile: InputPathType | None = None,
    extra_char: list[str] | None = None,
    runner: Runner | None = None,
) -> TokensOutputs:
    """
    tokens by AFNI Team.
    
    Token counting tool.
    
    More information:
    https://afni.nimh.nih.gov/pub/dist/doc/program_help/tokens.html
    
    Args:
        infile: Specify input file (stdin if none).
        extra_char: Specify extra character to count as valid. Can be used more\
            than once.
        runner: Command runner.
    Returns:
        NamedTuple of outputs (described in `TokensOutputs`).
    """
    runner = runner or get_global_runner()
    execution = runner.start_execution(TOKENS_METADATA)
    cargs = []
    cargs.append("tokens")
    if infile is not None:
        cargs.extend(["-infile", execution.input_file(infile)])
    if extra_char is not None:
        cargs.extend(["-extra", *extra_char])
    ret = TokensOutputs(
        root=execution.output_file("."),
    )
    execution.run(cargs)
    return ret


__all__ = [
    "TOKENS_METADATA",
    "TokensOutputs",
    "tokens",
]
